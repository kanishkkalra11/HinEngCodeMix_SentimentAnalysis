{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVizEtxjVgTh"
   },
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCpdNJpdqGOu"
   },
   "outputs": [],
   "source": [
    "fp = open(\"Dataset/train.txt\", 'r')\n",
    "raw_train = []\n",
    "trainsize = 0\n",
    "while(trainsize != 15131):\n",
    "  l = []\n",
    "  trainsize = trainsize+1\n",
    "  for line in fp:\n",
    "    line = line.strip()\n",
    "    if len(line.split()) > 1:\n",
    "      l.append(line.split())\n",
    "    if line == '':\n",
    "      raw_train.append(l)\n",
    "      break\n",
    "fp.close()\n",
    "\n",
    "fp = open(\"Dataset/test.txt\", 'r')\n",
    "raw_test = []\n",
    "testsize = 0\n",
    "while(testsize != 1869):\n",
    "  l = []\n",
    "  testsize = testsize + 1\n",
    "  for line in fp:\n",
    "    line = line.strip()\n",
    "    if len(line.split()) > 1:\n",
    "      l.append(line.split())\n",
    "    if line == '':\n",
    "      raw_test.append(l)\n",
    "      break\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAKrLUdC_Q2z"
   },
   "outputs": [],
   "source": [
    "y_train = []\n",
    "train_id = []\n",
    "for tweet in raw_train:\n",
    "  train_id.append(tweet[0][1])\n",
    "  y_train.append(tweet[0][2])\n",
    "\n",
    "y_test = []\n",
    "test_id = []\n",
    "for tweet in raw_test:\n",
    "  test_id.append(tweet[0][1])\n",
    "  y_test.append(tweet[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvhpDXShc0rT"
   },
   "outputs": [],
   "source": [
    "with open(\"Dataset/utils/y_train.txt\",'w') as f:\n",
    "  for id1, sentiment in zip(train_id, y_train):\n",
    "      f.write(id1+\"\\t\"+sentiment+\"\\n\")\n",
    "\n",
    "with open(\"Dataset/utils/y_test.txt\",'w') as f:\n",
    "  for id1, sentiment in zip(test_id, y_test):\n",
    "      f.write(id1+\"\\t\"+sentiment+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lb1bylRj_l3Z"
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(15131):\n",
    "  temp = []\n",
    "  for j in range(len(raw_train[i])):\n",
    "    if bool(re.match(\"^[a-zA-Z]+$\",raw_train[i][j][0])):\n",
    "      if bool(re.match(\"^(http)|(^t$)|(^co$)\",raw_train[i][j][0])):\n",
    "        continue\n",
    "      else:\n",
    "        raw_train[i][j][0] = raw_train[i][j][0].lower()\n",
    "        temp.append(raw_train[i][j])\n",
    "  train.append(temp[1:])\n",
    "\n",
    "test = []\n",
    "for i in range(1869):\n",
    "  temp = []\n",
    "  for j in range(len(raw_test[i])):\n",
    "    if bool(re.match(\"^[a-zA-Z]+$\",raw_test[i][j][0])):\n",
    "      if bool(re.match(\"^(http)|(^t$)|(^co$)\",raw_test[i][j][0])):\n",
    "        continue\n",
    "      else:\n",
    "        raw_test[i][j][0] = raw_test[i][j][0].lower()\n",
    "        temp.append(raw_test[i][j])\n",
    "  test.append(temp[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEkNw8x6aRfs"
   },
   "outputs": [],
   "source": [
    "with open(\"X_train.txt\",'w') as f:\n",
    "  for id1, tweet in zip(train_id, final_new_train):\n",
    "      f.write(id1+\"\\t\"+\" \".join([j[0] for j in tweet[1:-1]])+\"\\n\")\n",
    "\n",
    "with open(\"X_test.txt\",'w') as f:\n",
    "  for id1, tweet in zip(test_id, final_new_test):\n",
    "      f.write(id1+\"\\t\"+\" \".join([j[0] for j in tweet[1:-1]])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZ1mMHNYe_ak"
   },
   "outputs": [],
   "source": [
    "csvData = []\n",
    "fl = open('y_train.txt','r')\n",
    "fd = open('X_train.txt','r')\n",
    "linel = fl.readline()\n",
    "lined = fd.readline()\n",
    "while(linel):\n",
    "  csvData.append([])\n",
    "  index = linel.find('\\t')\n",
    "  csvData[-1].append(int(linel[:index]))\n",
    "  csvData[-1].append(lined[index+1:-1])\n",
    "  csvData[-1].append(linel[index+1:-1])\n",
    "  linel = fl.readline()\n",
    "  lined = fd.readline()\n",
    "fl.close()\n",
    "fd.close()\n",
    "\n",
    "with open('Dataset/processed_data/train.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(csvData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfHWU79VefGS"
   },
   "outputs": [],
   "source": [
    "csvData = []\n",
    "fl = open('y_test.txt','r')\n",
    "fd = open('X_test.txt','r')\n",
    "linel = fl.readline()\n",
    "lined = fd.readline()\n",
    "while(linel):\n",
    "  csvData.append([])\n",
    "  index = linel.find('\\t')\n",
    "  csvData[-1].append(int(linel[:index]))\n",
    "  csvData[-1].append(lined[index+1:-1])\n",
    "  csvData[-1].append(linel[index+1:-1])\n",
    "  linel = fl.readline()\n",
    "  lined = fd.readline()\n",
    "fl.close()\n",
    "fd.close()\n",
    "\n",
    "with open('Dataset/processed_data/test.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(csvData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/processed_data/train.csv')\n",
    "\n",
    "data = list(df['pakistan ka ghra tauq he pakistan israel ko tasleem nahein kerta isko palestine kehta he occupied'])\n",
    "labels = list(df['negative'])\n",
    "\n",
    "data = ['pakistan ka ghra tauq he pakistan israel ko tasleem nahein kerta isko palestine kehta he occupied'] + data\n",
    "labels = ['negative'] + labels\n",
    "\n",
    "with open('Dataset/processed_data/data.pkl','wb') as f:\n",
    "  p.dump(data,f)\n",
    "\n",
    "labelsfinal = []\n",
    "for i in range(len(labels)):\n",
    "  if labels[i] == 'negative':\n",
    "    labelsfinal.append(1)\n",
    "  elif labels[i] == 'neutral':\n",
    "    labelsfinal.append(2)\n",
    "  else:\n",
    "    labelsfinal.append(0)\n",
    "labelsfinal = np.array(labelsfinal)\n",
    "np.save('Dataset/processed_data/labels',labelsfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/processed_data/test.csv')\n",
    "\n",
    "data = list(df['uaapconfessions love looks good on maddie ako lang ba yung sobrang masaya kasi may zolo sya before with the past z medyo lowkey'])\n",
    "labels = list(df['neutral'])\n",
    "\n",
    "data = ['uaapconfessions love looks good on maddie ako lang ba yung sobrang masaya kasi may zolo sya before with the past z medyo lowkey'] + data\n",
    "labels = ['neutral'] + labels\n",
    "\n",
    "with open('Dataset/processed_data/datatest.pkl','wb') as f:\n",
    "  p.dump(data,f)\n",
    "\n",
    "labelsfinal = []\n",
    "for i in range(len(labels)):\n",
    "  if labels[i] == 'negative':\n",
    "    labelsfinal.append(1)\n",
    "  elif labels[i] == 'neutral':\n",
    "    labelsfinal.append(2)\n",
    "  else:\n",
    "    labelsfinal.append(0)\n",
    "labelsfinal = np.array(labelsfinal)\n",
    "np.save('Dataset/processed_data/labelstest',labelsfinal)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of assignment 3_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
